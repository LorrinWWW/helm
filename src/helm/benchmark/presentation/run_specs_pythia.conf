# Main `RunSpec`s for the benchmarking.

entries: [
  ##### Generic #####

#  ###### Question Answering #####
#  # Scenarios: BoolQ, NarrativeQA, NewsQA, QuAC
#  # Scenarios: NaturalQuestions
#  # Scenarios: CommonsenseQA, HellaSwag, OpenBookQA, TruthfulQA
#  # Scenarios: MMLU
#  
#  ## Reading comprehension
#  
#  #{description: "boolq:model=together/stablelm-base-alpha-7b-fix2", priority: 1}
#  {description: "narrative_qa:model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "quac:model=together/stablelm-base-alpha-7b-fix2", priority: 1}
#  
#  ## Reading comprehension and closedbook QA variants
#  
#  {description: "natural_qa:model=together/stablelm-base-alpha-7b-fix2,mode=openbook_longans", priority: 1}
#  {description: "natural_qa:model=together/stablelm-base-alpha-7b-fix2,mode=closedbook", priority: 1}
#  
#  ## Closed-book QA with multiple choice
#  
#  #{description: "commonsense:model=together/stablelm-base-alpha-7b-fix2,dataset=commonsenseqa,method=multiple_choice_separate_calibrated", priority: 3}
#  # Adaptation method is set to ADAPT_MULTIPLE_CHOICE_SEPARATE_CALIBRATED and echo=True
#  {description: "commonsense:model=together/stablelm-base-alpha-7b-fix2,dataset=hellaswag,method=multiple_choice_separate_original", priority: 1}
#  {description: "commonsense:model=together/stablelm-base-alpha-7b-fix2,dataset=openbookqa,method=multiple_choice_separate_calibrated", priority: 2}
#  {description: "truthful_qa:model=together/stablelm-base-alpha-7b-fix2,task=mc_single", priority: 1}
#  
#  # For MMLU, we sampled the following 10 subjects, which cover diverse topics across humanities, social sciences and STEM.
#  {description: "mmlu:model=together/stablelm-base-alpha-7b-fix2,subject=abstract_algebra", priority: 2}
#  {description: "mmlu:model=together/stablelm-base-alpha-7b-fix2,subject=college_chemistry", priority: 2}
#  {description: "mmlu:model=together/stablelm-base-alpha-7b-fix2,subject=computer_security", priority: 2}
#  {description: "mmlu:model=together/stablelm-base-alpha-7b-fix2,subject=econometrics", priority: 2}
#  {description: "mmlu:model=together/stablelm-base-alpha-7b-fix2,subject=us_foreign_policy", priority: 2}
#  
#  
#  ##### Information Retrieval #####
#  # Scenarios: MS Marco (Regular), MS MARCO (TREC)
#  
  {description: "msmarco:model=together/stablelm-base-alpha-7b-fix2,track=regular,valid_topk=30", priority: 2}
  {description: "msmarco:model=together/stablelm-base-alpha-7b-fix2,track=trec,valid_topk=30", priority: 1}
#  
#  ##### Summarization #####
#  # Scenarios: XSUM, CNN/DM
#  
#  {description: "summarization_cnndm:model=together/stablelm-base-alpha-7b-fix2,temperature=0.3,device=cpu", priority: 1}
#  {description: "summarization_xsum_sampled:model=together/stablelm-base-alpha-7b-fix2,temperature=0.3,device=cpu", priority: 1}
#  
#  
#  ##### Sentiment Analysis #####
#  # Scenarios: IMDB
#  
#  {description: "imdb:model=together/stablelm-base-alpha-7b-fix2", priority: 1}
#  
#  
#  ##### (Miscellaneous) Text Classification #####
#  # Scenarios: RAFT
#  
#  {description: "raft:subset=ade_corpus_v2,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=banking_77,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=neurips_impact_statement_risks,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=one_stop_english,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=overruling,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=semiconductor_org_types,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=tweet_eval_hate,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=twitter_complaints,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=systematic_review_inclusion,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=tai_safety_research,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  {description: "raft:subset=terms_of_service,model=together/stablelm-base-alpha-7b-fix2", priority: 2}
#  
#  
#  ##### Toxicity Detection #####
#  # Scenarios: CivilComments
#  
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=all", priority: 1}
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=male", priority: 2}
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=female", priority: 2}
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=LGBTQ", priority: 2}
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=christian", priority: 2}
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=muslim", priority: 2}
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=other_religions", priority: 2}
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=black", priority: 2}
#  {description: "civil_comments:model=together/stablelm-base-alpha-7b-fix2,demographic=white", priority: 2}
#
]
